{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Semi-supervised k-means\n",
    "Author: Bin Feng\n",
    "Date: 06/10/2019\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "# reference to\n",
    "# https://github.com/lsxliron/SemiSupervisedKMeans\n",
    "# https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/cluster/k_means_.py#L769\n",
    "\n",
    "class SemiKMeans(object):\n",
    "    \"\"\"\n",
    "    Attributes:\n",
    "        n_clusters: int, default: 8\n",
    "            the number of clusters to form as the number of centroids to generate\n",
    "        ### init: str, {'k-means++', 'random'}, default: k-means++\n",
    "            the method used to initialized centers\n",
    "            \"k-means++\": seelects initial centers in a smart way to speed up conveergence\n",
    "            \"random\": chooses k observations (rows) at random as initialized centers ###\n",
    "        max_iter: int, default: 300\n",
    "            max number of iterations of the semi-supervised k-means to run\n",
    "        distance_metric: str, {\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\", \"wminkowski\"} default: euclidean\n",
    "            metric used for pairwise distance calculation\n",
    "        labeled_data: list, 2D array\n",
    "            every cluster should be included in this 2D array including clusters with none labeled data. For example, \n",
    "            if we know some labeled data for cluster 0 and 2, and the total number of clusters is 3. Then, we have\n",
    "            ```\n",
    "            labeled_data = [np.array([1,2]), np.array([]), np.array([3,4])]\n",
    "            labeled_data with no element is not expected: labeled_data = [np.array([])]\n",
    "            ```\n",
    "        weight: float, default: 0.5\n",
    "            given different weight for labeled_data, range from [0, +inf)\n",
    "        verbose: boolen, default: 0\n",
    "            prints iterations and convergence rate if is 1\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_clusters=8, max_iter=300, distance_metric='euclidean', labeled_data=None, \n",
    "                 weight=0.5, tol=0.0001, verbose=0):\n",
    "        \"\"\"initialize SemiKmeans object\"\"\"\n",
    "        \n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.distance_metric = distance_metric\n",
    "        self.labeled_data = labeled_data\n",
    "        self.weight = float(weight)\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.centroids = None\n",
    "        self.label_ = None\n",
    "        \n",
    "    \n",
    "    def _get_distance(self, x, y):\n",
    "        \"\"\" \n",
    "            :param x: np.array, point 1\n",
    "            :param y: np.array, point 2\n",
    "            :return: float, distance between point 1 and point 2 defined by metric\n",
    "        \"\"\"\n",
    "        x = x.reshape(1,-1)\n",
    "        y = y.reshape(1,-1)\n",
    "        \n",
    "        return pairwise_distances(x, y, metric = self.distance_metric)[0]\n",
    "    \n",
    "    def _update_centroids(self, data):\n",
    "        \"\"\"\n",
    "            updating centroid by taking average of all points in a cluster\n",
    "            :param data: np.array all points coordinates\n",
    "        \"\"\"\n",
    "        for i in range(self.n_clusters):\n",
    "            self.centroids[i] = np.mean(data[np.where(self.label_ == i)], axis = 0)\n",
    "    \n",
    "    def _update_biased_centroids(self, data):\n",
    "        \"\"\"\n",
    "            updating centroid for semi-supuervised learning\n",
    "            :param data: np.array all points coordinates\n",
    "        \"\"\"\n",
    "        weights = np.ones(data.shape[0])   \n",
    "        labeled_data_idx = np.hstack(np.array(self.labeled_data).flat).astype(np.int)\n",
    "        weights[labeled_data_idx] = self.weight\n",
    "        weights = weights/weights.sum()   \n",
    "        \n",
    "        for i in range(self.n_clusters):\n",
    "            # compute centroid for every cluster\n",
    "            inds = np.where(self.label_==i)[0]\n",
    "            self.centroids[i] = np.average(data[inds], weights=weights[inds], axis=0)\n",
    "        \n",
    "        ''' if labeled_data_idx needed to be updated\n",
    "        for i in xrange(self.n_clusters):\n",
    "            if i<len(self.known_data) and len(self.known_data[i]):\n",
    "                max_vote = 0\n",
    "                max_vote = map(lambda lbl: (self.label_[self.known_data[i]]==lbl).sum() , range(0, self.n_clusters))\n",
    "                self.label_[self.known_data[i]] = np.argmax(max_vote)\n",
    "        '''\n",
    "    \n",
    "    def _kmeans_pp(self, data, n_local_trials = None):\n",
    "        \"\"\"\n",
    "            Initialize cluster centers using k-means++\n",
    "            :param data: np.array all points coordinates\n",
    "            :param n_local_trials : integer, optional\n",
    "                The number of seeding trials for each center (except the first/from labeled data),\n",
    "                of which the one reducing inertia the most is greedily chosen. Set to None to make \n",
    "                the number of trials depend logarithmically on the number of seeds (2+log(k)); this \n",
    "                is the default.\n",
    "            \n",
    "            Note\n",
    "            -----\n",
    "            Selects initial cluster centers for k-mean clustering in a smart way\n",
    "            to speed up convergence. see: Arthur, D. and Vassilvitskii, S.\n",
    "            \"k-means++: the advantages of careful seeding\". ACM-SIAM symposium\n",
    "            on Discrete algorithms. 2007\n",
    "        \"\"\"\n",
    "        # initialize labels to be the same size as data\n",
    "        self.label_ = np.zeros(len(data))\n",
    "        self.label_.fill(-1)\n",
    "        \n",
    "        # If we have some labeled data points, make them the centroid\n",
    "        # otherwise, follow k-means++ procedures\n",
    "        if self.labeled_data is not None:\n",
    "            current_centers = None\n",
    "            for i, pts in enumerate(self.labeled_data):\n",
    "                if len(pts):\n",
    "                    self.label_[pts] = i\n",
    "                    if current_centers is not None:\n",
    "                        current_centers = np.vstack((current_centers, np.mean(data[np.where(self.label_==i)], axis=0)))\n",
    "                    else:\n",
    "                        current_centers = np.mean(data[np.where(self.label_==i)], axis=0)\n",
    "                        current_centers = current_centers.reshape(1,len(current_centers))\n",
    "        \n",
    "        else:\n",
    "            # Choose the first centroid randomly as stated in kmeans++ procedures\n",
    "            first_centroid_index = np.random.choice(np.arange(0, len(data)), 1)\n",
    "            self.label_[first_centroid_index] = 0\n",
    "            current_centers = data[first_centroid_index]\n",
    "        \n",
    "        # initialize the rest centroids\n",
    "        for i in range(len(current_centers), self.n_clusters):\n",
    "            found_centroid = False\n",
    "            distances = np.array([min([self._get_distance(center, p) for center in current_centers]) for p in data], dtype=np.float64)\n",
    "            distances_sq = distances**2\n",
    "            probabilities = distances_sq/distances_sq.sum()\n",
    "            \n",
    "            # Set the number of local seeding trials.\n",
    "            # This is what Arthur/Vassilvitskii tried, but did not report\n",
    "            # specific results for other than mentioning in the conclusion\n",
    "            # that it helped.\n",
    "            n_local_trials = 2 + int(np.log(self.n_clusters))\n",
    "            \n",
    "            rand_vals = np.random.random_sample(n_local_trials)\n",
    "            candidate_ids = np.searchsorted(np.cumsum(probabilities), rand_vals)\n",
    "            \n",
    "            # Decide which candidate is the best\n",
    "            best_candidate = None\n",
    "            best_dist_sq = None\n",
    "            for trial in range(n_local_trials):\n",
    "                # Compute potential when including center candidate\n",
    "                new_dist_sq = distances_sq[candidate_ids[trial]]\n",
    "\n",
    "                # Store result if it is the best local trial so far\n",
    "                if (best_candidate is None) or (new_dist_sq < best_dist_sq):\n",
    "                    best_candidate = candidate_ids[trial]\n",
    "                    best_dist_sq = new_dist_sq\n",
    "\n",
    "            current_centers = np.vstack((current_centers, data[best_candidate]))\n",
    "            \n",
    "            next_label = 0\n",
    "            while next_label in set(self.label_):\n",
    "                next_label += 1\n",
    "            \n",
    "            self.label_[best_candidate] = next_label\n",
    "            \n",
    "        self.centroids = current_centers\n",
    "\n",
    "        \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "            :return: np.array, labels of the clustered data\n",
    "        \"\"\"\n",
    "        return self.label_\n",
    "        \n",
    "    def fit_predict(self, data):\n",
    "        \"\"\"\n",
    "            Clusteres the data and returns tha labels\n",
    "            :param data: np.ndarray, data to cluster\n",
    "            :return: np.array, data labels\n",
    "        \"\"\"\n",
    "        self.fit(data)\n",
    "        return self.predict()\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "            Clusters the data\n",
    "            :param data: np.ndarray, data to cluster\n",
    "        \"\"\"\n",
    "        # initializa centroids, labels, iteration times, threshold\n",
    "        self._kmeans_pp(data)\n",
    "        new_label = self.label_.copy()\n",
    "        counter = 0\n",
    "        tol = np.infty\n",
    "        \n",
    "        while counter < self.max_iter and self.tol < tol:\n",
    "            for i, p in enumerate(data):\n",
    "                new_label[i] = np.argmin([self._get_distance(center, p) for center in self.centroids])\n",
    "            \n",
    "            print(Counter(new_label))\n",
    "            old_centroids = self.centroids.copy()\n",
    "            self.label_ = new_label.copy()\n",
    "            \n",
    "            if self.labeled_data is not None:\n",
    "                self._update_biased_centroids(data)\n",
    "            else:\n",
    "                self._update_centroids(data)\n",
    "                \n",
    "            tol = abs(np.mean(old_centroids)-np.mean(self.centroids))\n",
    "\n",
    "            counter+=1\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(\"Iteration {}\\tConvergance: {}\".format(counter, tol))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "IRIS Dataset - Unsupervised K - Means\n",
      "Counter({1.0: 72, 0.0: 50, 2.0: 28})\n",
      "Iteration 1\tConvergance: 0.06937301587301636\n",
      "Counter({1.0: 66, 0.0: 50, 2.0: 34})\n",
      "Iteration 2\tConvergance: 0.03415669298022195\n",
      "Counter({1.0: 63, 0.0: 50, 2.0: 37})\n",
      "Iteration 3\tConvergance: 0.017380558557028802\n",
      "Counter({1.0: 59, 0.0: 50, 2.0: 41})\n",
      "Iteration 4\tConvergance: 0.02167613192830098\n",
      "Counter({1.0: 54, 0.0: 50, 2.0: 46})\n",
      "Iteration 5\tConvergance: 0.026265184128957397\n",
      "Counter({0.0: 50, 1.0: 50, 2.0: 50})\n",
      "Iteration 6\tConvergance: 0.020648416532473846\n",
      "Counter({2.0: 54, 0.0: 50, 1.0: 46})\n",
      "Iteration 7\tConvergance: 0.020977992485239128\n",
      "Counter({2.0: 57, 0.0: 50, 1.0: 43})\n",
      "Iteration 8\tConvergance: 0.016060223209036106\n",
      "Counter({2.0: 60, 0.0: 50, 1.0: 40})\n",
      "Iteration 9\tConvergance: 0.01696178430572548\n",
      "Counter({2.0: 61, 0.0: 50, 1.0: 39})\n",
      "Iteration 10\tConvergance: 0.005628415300546585\n",
      "Counter({2.0: 61, 0.0: 50, 1.0: 39})\n",
      "Iteration 11\tConvergance: 0.0\n",
      "\n",
      "Score:\t0.733118073528001\n",
      "\n",
      "\n",
      "IRIS Dataset - Semi - Supervised K - Means\n",
      "Counter({2.0: 56, 0.0: 51, 1.0: 43})\n",
      "Iteration 1\tConvergance: 0.002764020983071269\n",
      "Counter({2.0: 60, 0.0: 50, 1.0: 40})\n",
      "Iteration 2\tConvergance: 0.010921164202114753\n",
      "Counter({2.0: 61, 0.0: 50, 1.0: 39})\n",
      "Iteration 3\tConvergance: 0.005628415300546585\n",
      "Counter({2.0: 61, 0.0: 50, 1.0: 39})\n",
      "Iteration 4\tConvergance: 0.0\n",
      "\n",
      "Score:\t0.733118073528001\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bin/anaconda3/envs/research/lib/python3.7/site-packages/sklearn/metrics/cluster/supervised.py:746: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n",
      "/Users/bin/anaconda3/envs/research/lib/python3.7/site-packages/sklearn/metrics/cluster/supervised.py:746: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# test and example\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Load data\n",
    "    iris_data = load_iris()['data']\n",
    "    iris_labels = load_iris()['target']\n",
    "\n",
    "    cancer_data = load_breast_cancer()['data']\n",
    "    cancer_labels = load_breast_cancer()['target']\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "    # Give 20 data points from clusters 0 and 2\n",
    "    n = 20\n",
    "    iris_known_data = np.array([ np.random.choice(np.where(iris_labels==0)[0], n), [], np.random.choice(np.where(iris_labels==2)[0], n) ])\n",
    "\n",
    "    print(\"IRIS Dataset - Unsupervised K - Means\")\n",
    "    kmeans = SemiKMeans(n_clusters=3, verbose=True)\n",
    "    kmeans_results = kmeans.fit_predict(iris_data)\n",
    "    print(\"\\nScore:\\t{}\\n\\n\".format(adjusted_mutual_info_score(iris_labels, kmeans_results)))\n",
    "#     print(iris_labels)\n",
    "#     print(kmeans_results)\n",
    "\n",
    "\n",
    "    print(\"IRIS Dataset - Semi - Supervised K - Means\")\n",
    "    kmeans_semi = SemiKMeans(n_clusters=3, labeled_data=iris_known_data, weight=1, verbose=True)\n",
    "    kmeans_semi_results = kmeans_semi.fit_predict(iris_data)\n",
    "    print(\"\\nScore:\\t{}\\n\\n\".format(adjusted_mutual_info_score(iris_labels, kmeans_semi_results)))\n",
    "#     print(iris_labels)\n",
    "#     print(kmeans_semi_results)\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research] *",
   "language": "python",
   "name": "conda-env-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
