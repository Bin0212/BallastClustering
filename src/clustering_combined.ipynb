{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn import mixture\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from collections import Counter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import interpolate\n",
    "from scipy.spatial import distance\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions (general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_partnum(df1, df2):\n",
    "    \"\"\"\n",
    "    ensure dataframe df1 and df2 have same part_num\n",
    "    \"\"\"\n",
    "    # find part_num differences between two dataframes\n",
    "    diff1 = list(set(df1[\"part_num\"]) - set(df2[\"part_num\"]))\n",
    "    diff2 = list(set(df2[\"part_num\"]) - set(df1[\"part_num\"]))\n",
    "    \n",
    "    # drop rows containing part_num that only exist in one of the dataframes\n",
    "    del_row_idx1 = []\n",
    "    del_row_idx2 = []\n",
    "    for i in range(len(diff1)):\n",
    "        del_row_idx1.append(int(np.where(df1[\"part_num\"] == diff1[i])[0]))\n",
    "    df1 = df1.drop(del_row_idx1, axis=0)\n",
    "\n",
    "    for i in range(len(diff2)):\n",
    "        del_row_idx2.append(int(np.where(df2[\"part_num\"] == diff2[i])[0]))\n",
    "    df2 = df2.drop(del_row_idx2, axis=0)\n",
    "\n",
    "    # reset dataframe index to range(part_num), otherwise there is a mismatch of index between \n",
    "    # df1 and df2 since index won't be reassigned when droping rows. Such mismatch leads\n",
    "    # NaN values when calculating particle movement\n",
    "    df1 = df1.set_index(pd.Index(range(len(df1[\"part_num\"]))))\n",
    "    df2 = df2.set_index(pd.Index(range(len(df2[\"part_num\"]))))\n",
    "    \n",
    "    return df1, df2\n",
    "\n",
    "def drop_nan(df):\n",
    "    \"\"\"drop any rows containing NaNs\"\"\"\n",
    "    # find row index containing NaNs\n",
    "    row_idx = df.isnull().any(axis=1).to_numpy().nonzero()[0]\n",
    "    \n",
    "    # drop corresponding rows\n",
    "    df = df.drop(row_idx, axis=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def cross_section(df, x_range=None, y_range=None, z_range=None):\n",
    "    \"\"\"choose part_num within the given x, y, z range\"\"\"\n",
    "    \n",
    "    if x_range != None:\n",
    "        df = df.loc[(df['x'] >= x_range[0]) & (df['x'] <= x_range[1])]\n",
    "    if y_range != None:\n",
    "        df = df.loc[(df['y'] >= y_range[0]) & (df['y'] <= y_range[1])]\n",
    "    if z_range != None:\n",
    "        df = df.loc[(df['z'] >= z_range[0]) & (df['z'] <= z_range[1])]\n",
    "    \n",
    "    return df[\"part_num\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions (movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_movement(folder, step):\n",
    "    \"\"\"\n",
    "    read single step particle property file\n",
    "    \"\"\"\n",
    "    # define file path and read in the file as dataframe\n",
    "    file_path = \"../data/50mph/\" + str(folder) + \"/\" + str(folder) + str(step)\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "def _winsorization(df):\n",
    "    \"\"\"helper function to perform winsorization\"\"\"\n",
    "    # find the threshold for winsorization\n",
    "    p = 0.95\n",
    "    quantile_value = np.quantile(df, p)\n",
    "    \n",
    "    # apply winsorizaiton on the given column df\n",
    "    df = df.apply(lambda x: x if x < quantile_value else quantile_value)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_movement(df):\n",
    "    \"\"\"\n",
    "    collections of functions to preprocess dataframe before clustering analysis\n",
    "    \"\"\"\n",
    "    # change movement into absolute values\n",
    "    df.iloc[:,4:7] = np.abs(df.iloc[:,4:7])\n",
    "\n",
    "    # take natural logarithm for movement columns, min_value added to fix extreme value cases\n",
    "    min_value = 1e-5\n",
    "    df.iloc[:,4:7] = np.log(df.iloc[:,4:7] + min_value)\n",
    "    \n",
    "    # winsorization is not suitable for movement only clustering, it actually makes the clustering results worse\n",
    "    # df.iloc[:,4:7] = df.iloc[:,4:7].apply(_winsorization, axis = 0)\n",
    "    \n",
    "    # standardization \n",
    "    tmp = pd.DataFrame(preprocessing.scale(df.iloc[:,4:7]))\n",
    "    tmp = tmp.set_index(pd.Index(range(len(df[\"part_num\"]))))\n",
    "    tmp.columns = df.columns[4:7]\n",
    "    df.iloc[:,4:7] = tmp\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions (force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_force(folder):\n",
    "    \"\"\"\n",
    "    read particle property files for all 303 steps\n",
    "    forces in x,y,z directions are combined into one value for one step\n",
    "    different steps' values are saved in different columnes\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    # loop through all steps\n",
    "    for i in range(1,304):\n",
    "        file_path = \"../data/50mph/\" + str(folder) + \"/\" + str(folder) + \"_Step\" + str(i) + \".csv\"\n",
    "        tmp = pd.read_csv(file_path)\n",
    "        force = np.sqrt(tmp[\"F_x\"]**2 + \n",
    "                        tmp[\"F_y\"]**2 + \n",
    "                        tmp[\"F_z\"]**2)\n",
    "        data[str(i)] = force\n",
    "    \n",
    "    # add part_num, x, y, z coordinates at the begining to identify particles\n",
    "    data.insert(0, \"part_num\", tmp[\"part_num\"])\n",
    "    data.insert(1, \"x\", tmp[\"centroid_x\"])\n",
    "    data.insert(2, \"y\", tmp[\"centroid_y\"])\n",
    "    data.insert(3, \"z\", tmp[\"centroid_z\"])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def _gaussian_kernel(df_row, df_surround):\n",
    "    \"\"\"helper function for applying gaussian kernel\"\"\"\n",
    "    # set weights for spatial 3x3 gaussian kernel\n",
    "    weights = [4, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    \n",
    "    # apply gaussian kernel for the corresponding particle df_row\n",
    "    output = df_surround.multiply(weights, axis=0).copy()\n",
    "    output = output.sum(axis=0)/sum(weights)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def apply_kernel(df, top_idx):\n",
    "    \"\"\"\n",
    "    apply kernel functions to all the particles\n",
    "    \"\"\"\n",
    "    # copy the df so that any modification on the tmp won't affect the original df\n",
    "    tmp = df.copy()\n",
    "\n",
    "    # loop through all particles\n",
    "    for i in range(len(top_idx)):\n",
    "        tmp.iloc[i,1:] = _gaussian_kernel(df.iloc[i,1:], df.iloc[top_idx[i],1:])\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "def sort_idx(array):\n",
    "    \"\"\"find the top nth particles that are closest to the target particle\"\"\"\n",
    "    # find the top nth particle indexes using np.argsort()\n",
    "    top_idx = np.argsort(array)[:19]\n",
    "    return top_idx\n",
    "\n",
    "def spline_validate(data, knots, labels, mask):\n",
    "    \"\"\"\n",
    "    perform 10-fold cross validation on a given number of knots\n",
    "    \"\"\"\n",
    "    # divide into train and validate datasets\n",
    "    idx_train = [idx for idx, label in enumerate(labels) if label != mask]\n",
    "    idx_val = [idx for idx, label in enumerate(labels) if label == mask]\n",
    "    \n",
    "    # calculate B-spline coefficients based on training data\n",
    "    x_train = np.linspace(0, total_time, num = len(idx_train))\n",
    "    y_train = data.iloc[idx_train]\n",
    "    tck = interpolate.splrep(x_train, y_train, task = -1, k = 3, t = knots)\n",
    "    \n",
    "    # predict y values for validation data\n",
    "    x_val = [i * time_interval * record_per_step for i in idx_val]\n",
    "    y_pred = interpolate.splev(x_val, tck)\n",
    "    y_val = data.iloc[idx_val]\n",
    "    \n",
    "    # return sum of squared errors\n",
    "    return np.sum((y_pred - y_val)**2)\n",
    "\n",
    "def get_spline_coef(data, knots):\n",
    "    \"\"\"\n",
    "    get B-spline coefficients for a given knots\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, total_time, num = len(data))\n",
    "    tck = interpolate.splrep(x, data, task = -1, k = 3, t = knots)\n",
    "    \n",
    "    return tck[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center Binding\n",
    "### Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_num</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>movement_x</th>\n",
       "      <th>movement_y</th>\n",
       "      <th>movement_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.590680</td>\n",
       "      <td>0.464698</td>\n",
       "      <td>0.219044</td>\n",
       "      <td>-0.794319</td>\n",
       "      <td>-0.566342</td>\n",
       "      <td>-1.776663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.621595</td>\n",
       "      <td>0.528801</td>\n",
       "      <td>0.239288</td>\n",
       "      <td>-0.357824</td>\n",
       "      <td>-0.864936</td>\n",
       "      <td>-0.630764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1.065077</td>\n",
       "      <td>0.488288</td>\n",
       "      <td>0.261308</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>-0.654721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1.063221</td>\n",
       "      <td>0.464308</td>\n",
       "      <td>0.219340</td>\n",
       "      <td>-0.295545</td>\n",
       "      <td>-0.525444</td>\n",
       "      <td>-0.819954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1.481332</td>\n",
       "      <td>0.583164</td>\n",
       "      <td>0.214781</td>\n",
       "      <td>0.167312</td>\n",
       "      <td>-0.303063</td>\n",
       "      <td>-2.364443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   part_num         x         y         z  movement_x  movement_y  movement_z\n",
       "0         1  0.590680  0.464698  0.219044   -0.794319   -0.566342   -1.776663\n",
       "1         2  0.621595  0.528801  0.239288   -0.357824   -0.864936   -0.630764\n",
       "2         5  1.065077  0.488288  0.261308    0.086207    0.006941   -0.654721\n",
       "3         6  1.063221  0.464308  0.219340   -0.295545   -0.525444   -0.819954\n",
       "4         7  1.481332  0.583164  0.214781    0.167312   -0.303063   -2.364443"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set folder name and file name\n",
    "folder_init, folder_final = \"cb_d9out\", \"cb_d16out\"\n",
    "step_init, step_final = \"_Step1.csv\", \"_Step303.csv\"\n",
    "\n",
    "# read initial state file and final state file\n",
    "init_state = read_data(folder_init, step_init)\n",
    "final_state = read_data(folder_final, step_final)\n",
    "\n",
    "# remove particles not exist in both files \n",
    "init_state, final_state = match_partnum(init_state, final_state)\n",
    "\n",
    "# calculate particle movement in x, y, z directions\n",
    "data_movement = []\n",
    "data_movement = final_state.iloc[:,2:5] - init_state.iloc[:,2:5]\n",
    "\n",
    "# finalize particle movement dataframe\n",
    "data_movement = pd.concat([final_state[\"part_num\"].astype(int), final_state.iloc[:,2:5],\n",
    "                           data_movement], axis=1)\n",
    "data_movement.index.name = \"\"\n",
    "data_movement.columns = ['part_num', 'x', 'y', 'z', 'movement_x', 'movement_y', 'movement_z']\n",
    "\n",
    "# preprocess dataframe\n",
    "data_movement = preprocess_movement(data_movement)\n",
    "# drop part_num 3, 4 because of excessive y-axis force\n",
    "data_movement = data_movement.drop([2,3]).reset_index(drop=True)\n",
    "data_movement.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force (get coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_num</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.299701</td>\n",
       "      <td>3.337575</td>\n",
       "      <td>5.179921</td>\n",
       "      <td>2.212083</td>\n",
       "      <td>5.260065</td>\n",
       "      <td>2.785450</td>\n",
       "      <td>3.797151</td>\n",
       "      <td>4.475549</td>\n",
       "      <td>3.105089</td>\n",
       "      <td>...</td>\n",
       "      <td>4.233866</td>\n",
       "      <td>3.467226</td>\n",
       "      <td>3.506617</td>\n",
       "      <td>4.459713</td>\n",
       "      <td>3.268414</td>\n",
       "      <td>3.802916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.922578</td>\n",
       "      <td>2.892079</td>\n",
       "      <td>4.228307</td>\n",
       "      <td>2.374619</td>\n",
       "      <td>4.111505</td>\n",
       "      <td>2.739753</td>\n",
       "      <td>3.256605</td>\n",
       "      <td>3.633913</td>\n",
       "      <td>2.944105</td>\n",
       "      <td>...</td>\n",
       "      <td>3.248430</td>\n",
       "      <td>2.831840</td>\n",
       "      <td>2.786175</td>\n",
       "      <td>4.200040</td>\n",
       "      <td>2.509484</td>\n",
       "      <td>3.474262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.318893</td>\n",
       "      <td>9.900917</td>\n",
       "      <td>8.413347</td>\n",
       "      <td>3.600088</td>\n",
       "      <td>9.275679</td>\n",
       "      <td>3.576467</td>\n",
       "      <td>7.561299</td>\n",
       "      <td>6.085863</td>\n",
       "      <td>6.349360</td>\n",
       "      <td>...</td>\n",
       "      <td>12.248132</td>\n",
       "      <td>2.293151</td>\n",
       "      <td>11.100057</td>\n",
       "      <td>5.926443</td>\n",
       "      <td>5.504911</td>\n",
       "      <td>5.563117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.301924</td>\n",
       "      <td>8.943700</td>\n",
       "      <td>7.693325</td>\n",
       "      <td>2.818763</td>\n",
       "      <td>7.348031</td>\n",
       "      <td>3.669454</td>\n",
       "      <td>7.604536</td>\n",
       "      <td>5.926053</td>\n",
       "      <td>6.125032</td>\n",
       "      <td>...</td>\n",
       "      <td>10.022411</td>\n",
       "      <td>1.038866</td>\n",
       "      <td>10.624730</td>\n",
       "      <td>2.668798</td>\n",
       "      <td>6.174754</td>\n",
       "      <td>4.124780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.522549</td>\n",
       "      <td>17.111072</td>\n",
       "      <td>51.799877</td>\n",
       "      <td>-9.558476</td>\n",
       "      <td>37.535798</td>\n",
       "      <td>4.314476</td>\n",
       "      <td>7.477634</td>\n",
       "      <td>6.831913</td>\n",
       "      <td>5.999019</td>\n",
       "      <td>...</td>\n",
       "      <td>41.761705</td>\n",
       "      <td>3.586591</td>\n",
       "      <td>29.421441</td>\n",
       "      <td>28.889488</td>\n",
       "      <td>-5.857956</td>\n",
       "      <td>10.223408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   part_num         0          1          2         3          4         5  \\\n",
       "0       1.0  3.299701   3.337575   5.179921  2.212083   5.260065  2.785450   \n",
       "1       2.0  2.922578   2.892079   4.228307  2.374619   4.111505  2.739753   \n",
       "2       5.0  3.318893   9.900917   8.413347  3.600088   9.275679  3.576467   \n",
       "3       6.0  3.301924   8.943700   7.693325  2.818763   7.348031  3.669454   \n",
       "4       7.0  7.522549  17.111072  51.799877 -9.558476  37.535798  4.314476   \n",
       "\n",
       "          6         7         8  ...         18        19         20  \\\n",
       "0  3.797151  4.475549  3.105089  ...   4.233866  3.467226   3.506617   \n",
       "1  3.256605  3.633913  2.944105  ...   3.248430  2.831840   2.786175   \n",
       "2  7.561299  6.085863  6.349360  ...  12.248132  2.293151  11.100057   \n",
       "3  7.604536  5.926053  6.125032  ...  10.022411  1.038866  10.624730   \n",
       "4  7.477634  6.831913  5.999019  ...  41.761705  3.586591  29.421441   \n",
       "\n",
       "          21        22         23   24   25   26   27  \n",
       "0   4.459713  3.268414   3.802916  0.0  0.0  0.0  0.0  \n",
       "1   4.200040  2.509484   3.474262  0.0  0.0  0.0  0.0  \n",
       "2   5.926443  5.504911   5.563117  0.0  0.0  0.0  0.0  \n",
       "3   2.668798  6.174754   4.124780  0.0  0.0  0.0  0.0  \n",
       "4  28.889488 -5.857956  10.223408  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in files\n",
    "folder = \"cb_d16out\"\n",
    "data_force = read_data_force(folder).drop([2,3])\n",
    "\n",
    "# read and averaging b-spline coefficients for eight train passes\n",
    "spline_coef = pd.DataFrame()\n",
    "\n",
    "for i in range(8):\n",
    "    if spline_coef.empty:\n",
    "        file = '../output/spline_coef_cb_' + str(i+9) + '.csv'\n",
    "        spline_coef = pd.read_csv(file)\n",
    "        spline_coef = drop_nan(spline_coef)\n",
    "    else:\n",
    "        \n",
    "        file = '../output/spline_coef_cb_' + str(i+9) + '.csv'\n",
    "        tmp = pd.read_csv(file)\n",
    "        tmp = drop_nan(tmp)\n",
    "        spline_coef, tmp = match_partnum(spline_coef, tmp)\n",
    "        spline_coef = spline_coef.add(tmp)/2\n",
    "\n",
    "# get particle x,y,z coordinates\n",
    "data_force = drop_nan(data_force)\n",
    "data_force, spline_coef = match_partnum(data_force, spline_coef)\n",
    "coord = data_force.iloc[:,1:4]\n",
    "\n",
    "# calculate pairwise distance between all particles\n",
    "dist = distance.cdist(coord, coord, 'euclidean')\n",
    "# get the index for the closest 19 coordinates\n",
    "top_idx = np.apply_along_axis(sort_idx, 1, dist)\n",
    "# apply spatial 3x3 gaussian kernel to all particles\n",
    "spline_kernel = apply_kernel(spline_coef, top_idx)\n",
    "spline_kernel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force (apply PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st dir</th>\n",
       "      <th>2nd dir</th>\n",
       "      <th>3rd dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.323422</td>\n",
       "      <td>1.091531</td>\n",
       "      <td>0.321381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.882633</td>\n",
       "      <td>0.844425</td>\n",
       "      <td>0.282777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.027414</td>\n",
       "      <td>2.263979</td>\n",
       "      <td>-0.569943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.584310</td>\n",
       "      <td>2.247445</td>\n",
       "      <td>-0.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.661811</td>\n",
       "      <td>1.930022</td>\n",
       "      <td>-0.330671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1st dir   2nd dir   3rd dir\n",
       "0 -3.323422  1.091531  0.321381\n",
       "1 -3.882633  0.844425  0.282777\n",
       "2 -1.027414  2.263979 -0.569943\n",
       "3 -1.584310  2.247445 -0.747500\n",
       "4  0.661811  1.930022 -0.330671"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess spline coefficients with kernel function applied\n",
    "spline_kernel_raw = np.log(np.abs(spline_kernel.iloc[:,5:25])+0.0001)\n",
    "# apply standardizaiton and PCA\n",
    "spline_kernel_std = StandardScaler().fit_transform(spline_kernel_raw)\n",
    "spline_kernel_pca = PCA(n_components=3).fit_transform(spline_kernel_std)\n",
    "spline_kernel_pca = pd.DataFrame(spline_kernel_pca)\n",
    "spline_kernel_pca.columns = ['1st dir', '2nd dir', '3rd dir']\n",
    "spline_kernel_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movement_x</th>\n",
       "      <th>movement_y</th>\n",
       "      <th>movement_z</th>\n",
       "      <th>1st dir</th>\n",
       "      <th>2nd dir</th>\n",
       "      <th>3rd dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.794883</td>\n",
       "      <td>-0.566400</td>\n",
       "      <td>-1.777388</td>\n",
       "      <td>-0.988295</td>\n",
       "      <td>0.588824</td>\n",
       "      <td>0.285303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.358243</td>\n",
       "      <td>-0.864980</td>\n",
       "      <td>-0.631221</td>\n",
       "      <td>-1.154589</td>\n",
       "      <td>0.455523</td>\n",
       "      <td>0.251033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085935</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>-0.655184</td>\n",
       "      <td>-0.305525</td>\n",
       "      <td>1.221298</td>\n",
       "      <td>-0.505962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.295943</td>\n",
       "      <td>-0.525504</td>\n",
       "      <td>-0.820455</td>\n",
       "      <td>-0.471131</td>\n",
       "      <td>1.212379</td>\n",
       "      <td>-0.663586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.167067</td>\n",
       "      <td>-0.303134</td>\n",
       "      <td>-2.365305</td>\n",
       "      <td>0.196805</td>\n",
       "      <td>1.041146</td>\n",
       "      <td>-0.293550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movement_x  movement_y  movement_z   1st dir   2nd dir   3rd dir\n",
       "0   -0.794883   -0.566400   -1.777388 -0.988295  0.588824  0.285303\n",
       "1   -0.358243   -0.864980   -0.631221 -1.154589  0.455523  0.251033\n",
       "2    0.085935    0.006856   -0.655184 -0.305525  1.221298 -0.505962\n",
       "3   -0.295943   -0.525504   -0.820455 -0.471131  1.212379 -0.663586\n",
       "4    0.167067   -0.303134   -2.365305  0.196805  1.041146 -0.293550"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both movement and force features\n",
    "feature = pd.concat([data_movement.iloc[:,4:7], spline_kernel_pca], axis=1)\n",
    "# standardize features for clustering\n",
    "feature_std = pd.DataFrame(columns = col_name)\n",
    "feature_std = StandardScaler().fit_transform(feature)\n",
    "feature_std = pd.DataFrame(feature_std)\n",
    "feature_std.columns = ['movement_x', 'movement_y', 'movement_z', '1st dir', '2nd dir', '3rd dir']\n",
    "feature_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a36775940>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# get a intuition of data distributions\n",
    "sns.distplot(pd.DataFrame(feature_std[\"2nd dir\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4: 3112, 0: 3082, 1: 1853, 3: 1700, 2: 1677})\n"
     ]
    }
   ],
   "source": [
    "# if use spline_kernel for clustering with some preprocessing\n",
    "kmeans = cluster.KMeans(n_clusters = 5, n_init = 10, random_state = 0).fit(feature_std)\n",
    "\n",
    "# check clustering distribution\n",
    "print(Counter(kmeans.labels_))\n",
    "\n",
    "# save labels to a csv file\n",
    "label = pd.DataFrame({'part_num':spline_kernel[\"part_num\"],'label':kmeans.labels_})\n",
    "label.to_csv('../output/labels_combine_cb.csv',header=True, index=False)\n",
    "\n",
    "# visualization\n",
    "vs.plot('../output/labels_combine_cb.csv', 'CenterBinding.v3d','library.vlb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Support\n",
    "### Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_num</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>movement_x</th>\n",
       "      <th>movement_y</th>\n",
       "      <th>movement_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.588429</td>\n",
       "      <td>0.464272</td>\n",
       "      <td>0.217803</td>\n",
       "      <td>-1.324526</td>\n",
       "      <td>-1.573638</td>\n",
       "      <td>-2.589553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.618625</td>\n",
       "      <td>0.528252</td>\n",
       "      <td>0.237772</td>\n",
       "      <td>-0.540996</td>\n",
       "      <td>-0.764423</td>\n",
       "      <td>-0.923271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1.063574</td>\n",
       "      <td>0.488989</td>\n",
       "      <td>0.261487</td>\n",
       "      <td>0.214216</td>\n",
       "      <td>-0.367803</td>\n",
       "      <td>0.144108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1.060801</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>0.219256</td>\n",
       "      <td>-0.011536</td>\n",
       "      <td>-0.496512</td>\n",
       "      <td>-0.986408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1.487653</td>\n",
       "      <td>0.585113</td>\n",
       "      <td>0.214780</td>\n",
       "      <td>-0.733234</td>\n",
       "      <td>-1.250567</td>\n",
       "      <td>-2.554587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   part_num         x         y         z  movement_x  movement_y  movement_z\n",
       "0         1  0.588429  0.464272  0.217803   -1.324526   -1.573638   -2.589553\n",
       "1         2  0.618625  0.528252  0.237772   -0.540996   -0.764423   -0.923271\n",
       "2         5  1.063574  0.488989  0.261487    0.214216   -0.367803    0.144108\n",
       "3         6  1.060801  0.464395  0.219256   -0.011536   -0.496512   -0.986408\n",
       "4         7  1.487653  0.585113  0.214780   -0.733234   -1.250567   -2.554587"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set folder name and file name\n",
    "folder_init, folder_final = \"fs_d7out\", \"fs_d14out\"\n",
    "step_init, step_final = \"_Step1.csv\", \"_Step303.csv\"\n",
    "\n",
    "# read initial state file and final state file\n",
    "init_state = read_data(folder_init, step_init)\n",
    "final_state = read_data(folder_final, step_final)\n",
    "\n",
    "# remove particles not exist in both files \n",
    "init_state, final_state = match_partnum(init_state, final_state)\n",
    "\n",
    "# calculate particle movement in x, y, z directions\n",
    "data_movement = []\n",
    "data_movement = final_state.iloc[:,2:5] - init_state.iloc[:,2:5]\n",
    "\n",
    "# finalize particle movement dataframe\n",
    "data_movement = pd.concat([final_state[\"part_num\"].astype(int), final_state.iloc[:,2:5],\n",
    "                           data_movement], axis=1)\n",
    "data_movement.index.name = \"\"\n",
    "data_movement.columns = ['part_num', 'x', 'y', 'z', 'movement_x', 'movement_y', 'movement_z']\n",
    "\n",
    "# preprocess dataframe\n",
    "data_movement = preprocess_movement(data_movement)\n",
    "# drop part_num 3, 4 because of excessive y-axis force\n",
    "data_movement = data_movement.drop([2,3]).reset_index(drop=True)\n",
    "data_movement.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st dir</th>\n",
       "      <th>2nd dir</th>\n",
       "      <th>3rd dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.973367</td>\n",
       "      <td>1.670281</td>\n",
       "      <td>0.068854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.398161</td>\n",
       "      <td>0.915904</td>\n",
       "      <td>-0.224626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.124565</td>\n",
       "      <td>3.120371</td>\n",
       "      <td>0.478073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.658993</td>\n",
       "      <td>2.305020</td>\n",
       "      <td>0.380434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.087560</td>\n",
       "      <td>3.004178</td>\n",
       "      <td>0.696759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1st dir   2nd dir   3rd dir\n",
       "0 -1.973367  1.670281  0.068854\n",
       "1 -3.398161  0.915904 -0.224626\n",
       "2  1.124565  3.120371  0.478073\n",
       "3  0.658993  2.305020  0.380434\n",
       "4  3.087560  3.004178  0.696759"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in files\n",
    "folder = \"fs_d14out\"\n",
    "data_force = read_data_force(folder).drop([2,3])\n",
    "\n",
    "# read and averaging b-spline coefficients for eight train passes\n",
    "spline_coef = pd.DataFrame()\n",
    "\n",
    "for i in range(8):\n",
    "    if spline_coef.empty:\n",
    "        file = '../output/spline_coef_fs_' + str(i+7) + '.csv'\n",
    "        spline_coef = pd.read_csv(file)\n",
    "        spline_coef = drop_nan(spline_coef)\n",
    "    else:\n",
    "        \n",
    "        file = '../output/spline_coef_fs_' + str(i+7) + '.csv'\n",
    "        tmp = pd.read_csv(file)\n",
    "        tmp = drop_nan(tmp)\n",
    "        spline_coef, tmp = match_partnum(spline_coef, tmp)\n",
    "        spline_coef = spline_coef.add(tmp)/2\n",
    "\n",
    "# get particle x,y,z coordinates\n",
    "data_force = drop_nan(data_force)\n",
    "data_force, spline_coef = match_partnum(data_force, spline_coef)\n",
    "coord = data_force.iloc[:,1:4]\n",
    "\n",
    "# calculate pairwise distance between all particles\n",
    "dist = distance.cdist(coord, coord, 'euclidean')\n",
    "# get the index for the closest 19 coordinates\n",
    "top_idx = np.apply_along_axis(sort_idx, 1, dist)\n",
    "# apply spatial 3x3 gaussian kernel to all particles\n",
    "spline_kernel = apply_kernel(spline_coef, top_idx)\n",
    "\n",
    "# preprocess spline coefficients with kernel function applied\n",
    "spline_kernel_raw = np.log(np.abs(spline_kernel.iloc[:,5:25])+0.0001)\n",
    "# apply standardizaiton and PCA\n",
    "spline_kernel_std = StandardScaler().fit_transform(spline_kernel_raw)\n",
    "spline_kernel_pca = PCA(n_components=3).fit_transform(spline_kernel_std)\n",
    "spline_kernel_pca = pd.DataFrame(spline_kernel_pca)\n",
    "spline_kernel_pca.columns = ['1st dir', '2nd dir', '3rd dir']\n",
    "spline_kernel_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movement_x</th>\n",
       "      <th>movement_y</th>\n",
       "      <th>movement_z</th>\n",
       "      <th>1st dir</th>\n",
       "      <th>2nd dir</th>\n",
       "      <th>3rd dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.325285</td>\n",
       "      <td>-1.573736</td>\n",
       "      <td>-2.590722</td>\n",
       "      <td>-0.598369</td>\n",
       "      <td>0.902196</td>\n",
       "      <td>0.056703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.541497</td>\n",
       "      <td>-0.764534</td>\n",
       "      <td>-0.923922</td>\n",
       "      <td>-1.030398</td>\n",
       "      <td>0.494722</td>\n",
       "      <td>-0.184984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.213963</td>\n",
       "      <td>-0.367920</td>\n",
       "      <td>0.143788</td>\n",
       "      <td>0.340993</td>\n",
       "      <td>1.685457</td>\n",
       "      <td>0.393703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.011864</td>\n",
       "      <td>-0.496627</td>\n",
       "      <td>-0.987079</td>\n",
       "      <td>0.199821</td>\n",
       "      <td>1.245048</td>\n",
       "      <td>0.313295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.733799</td>\n",
       "      <td>-1.250670</td>\n",
       "      <td>-2.555745</td>\n",
       "      <td>0.936217</td>\n",
       "      <td>1.622696</td>\n",
       "      <td>0.573795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movement_x  movement_y  movement_z   1st dir   2nd dir   3rd dir\n",
       "0   -1.325285   -1.573736   -2.590722 -0.598369  0.902196  0.056703\n",
       "1   -0.541497   -0.764534   -0.923922 -1.030398  0.494722 -0.184984\n",
       "2    0.213963   -0.367920    0.143788  0.340993  1.685457  0.393703\n",
       "3   -0.011864   -0.496627   -0.987079  0.199821  1.245048  0.313295\n",
       "4   -0.733799   -1.250670   -2.555745  0.936217  1.622696  0.573795"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both movement and force features\n",
    "feature = pd.concat([data_movement.iloc[:,4:7], spline_kernel_pca], axis=1)\n",
    "# standardize features for clustering\n",
    "feature_std = pd.DataFrame(columns = col_name)\n",
    "feature_std = StandardScaler().fit_transform(feature)\n",
    "feature_std = pd.DataFrame(feature_std)\n",
    "feature_std.columns = ['movement_x', 'movement_y', 'movement_z', '1st dir', '2nd dir', '3rd dir']\n",
    "feature_std.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4: 2928, 3: 2601, 2: 1900, 0: 1702, 1: 1486})\n"
     ]
    }
   ],
   "source": [
    "# if use spline_kernel for clustering with some preprocessing\n",
    "kmeans = cluster.KMeans(n_clusters = 5, n_init = 10, random_state = 0).fit(feature_std)\n",
    "\n",
    "# check clustering distribution\n",
    "print(Counter(kmeans.labels_))\n",
    "\n",
    "# save labels to a csv file\n",
    "label = pd.DataFrame({'part_num':spline_kernel[\"part_num\"],'label':kmeans.labels_})\n",
    "label.to_csv('../output/labels_combine_fs.csv',header=True, index=False)\n",
    "\n",
    "# visualization\n",
    "vs.plot('../output/labels_combine_fs.csv', 'FullSup.v3d','library.vlb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lack of Center Support\n",
    "### Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11403, 7)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set folder name and file name\n",
    "folder_init, folder_final = \"locs_d9out\", \"locs_d16out\"\n",
    "step_init, step_final = \"_Step1.csv\", \"_Step303.csv\"\n",
    "\n",
    "# read initial state file and final state file\n",
    "init_state = read_data(folder_init, step_init)\n",
    "final_state = read_data(folder_final, step_final)\n",
    "\n",
    "# remove particles not exist in both files \n",
    "init_state, final_state = match_partnum(init_state, final_state)\n",
    "\n",
    "# calculate particle movement in x, y, z directions\n",
    "data_movement = []\n",
    "data_movement = final_state.iloc[:,2:5] - init_state.iloc[:,2:5]\n",
    "\n",
    "# finalize particle movement dataframe\n",
    "data_movement = pd.concat([final_state[\"part_num\"].astype(int), final_state.iloc[:,2:5],\n",
    "                           data_movement], axis=1)\n",
    "data_movement.index.name = \"\"\n",
    "data_movement.columns = ['part_num', 'x', 'y', 'z', 'movement_x', 'movement_y', 'movement_z']\n",
    "\n",
    "# preprocess dataframe\n",
    "data_movement = preprocess_movement(data_movement)\n",
    "# drop part_num 3, 4 because of excessive y-axis force\n",
    "data_movement = data_movement.drop([2,3]).reset_index(drop=True)\n",
    "data_movement.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11403, 3)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in files\n",
    "folder = \"locs_d16out\"\n",
    "data_force = read_data_force(folder).drop([2,3])\n",
    "\n",
    "# read and averaging b-spline coefficients for eight train passes\n",
    "spline_coef = pd.DataFrame()\n",
    "\n",
    "for i in range(8):\n",
    "    if spline_coef.empty:\n",
    "        file = '../output/spline_coef_locs_' + str(i+9) + '.csv'\n",
    "        spline_coef = pd.read_csv(file)\n",
    "        spline_coef = drop_nan(spline_coef)\n",
    "    else:\n",
    "        \n",
    "        file = '../output/spline_coef_locs_' + str(i+9) + '.csv'\n",
    "        tmp = pd.read_csv(file)\n",
    "        tmp = drop_nan(tmp)\n",
    "        spline_coef, tmp = match_partnum(spline_coef, tmp)\n",
    "        spline_coef = spline_coef.add(tmp)/2\n",
    "\n",
    "# get particle x,y,z coordinates\n",
    "data_force = drop_nan(data_force)\n",
    "data_force, spline_coef = match_partnum(data_force, spline_coef)\n",
    "coord = data_force.iloc[:,1:4]\n",
    "\n",
    "# calculate pairwise distance between all particles\n",
    "dist = distance.cdist(coord, coord, 'euclidean')\n",
    "# get the index for the closest 19 coordinates\n",
    "top_idx = np.apply_along_axis(sort_idx, 1, dist)\n",
    "# apply spatial 3x3 gaussian kernel to all particles\n",
    "spline_kernel = apply_kernel(spline_coef, top_idx)\n",
    "\n",
    "# preprocess spline coefficients with kernel function applied\n",
    "spline_kernel_raw = np.log(np.abs(spline_kernel.iloc[:,5:25])+0.0001)\n",
    "# apply standardizaiton and PCA\n",
    "spline_kernel_std = StandardScaler().fit_transform(spline_kernel_raw)\n",
    "spline_kernel_pca = PCA(n_components=3).fit_transform(spline_kernel_std)\n",
    "spline_kernel_pca = pd.DataFrame(spline_kernel_pca)\n",
    "spline_kernel_pca.columns = ['1st dir', '2nd dir', '3rd dir']\n",
    "spline_kernel_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11403, 6)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both movement and force features\n",
    "feature = pd.concat([data_movement.iloc[:,4:7], spline_kernel_pca], axis=1)\n",
    "# standardize features for clustering\n",
    "feature_std = pd.DataFrame(columns = col_name)\n",
    "feature_std = StandardScaler().fit_transform(feature)\n",
    "feature_std = pd.DataFrame(feature_std)\n",
    "feature_std.columns = ['movement_x', 'movement_y', 'movement_z', '1st dir', '2nd dir', '3rd dir']\n",
    "feature_std.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3251, 1: 2342, 3: 2202, 4: 1985, 2: 1623})\n"
     ]
    }
   ],
   "source": [
    "# if use spline_kernel for clustering with some preprocessing\n",
    "kmeans = cluster.KMeans(n_clusters = 5, n_init = 10, random_state = 0).fit(feature_std)\n",
    "\n",
    "# check clustering distribution\n",
    "print(Counter(kmeans.labels_))\n",
    "\n",
    "# save labels to a csv file\n",
    "label = pd.DataFrame({'part_num':spline_kernel[\"part_num\"],'label':kmeans.labels_})\n",
    "label.to_csv('../output/labels_combine_locs.csv',header=True, index=False)\n",
    "\n",
    "# visualization\n",
    "vs.plot('../output/labels_combine_locs.csv', 'LackofCenterSup.v3d','library.vlb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lack of Rail Seat Support\n",
    "### Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11775, 7)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set folder name and file name\n",
    "folder_init, folder_final = \"lorss_d13out\", \"lorss_d20out\"\n",
    "step_init, step_final = \"_Step1.csv\", \"_Step303.csv\"\n",
    "\n",
    "# read initial state file and final state file\n",
    "init_state = read_data(folder_init, step_init)\n",
    "final_state = read_data(folder_final, step_final)\n",
    "\n",
    "# remove particles not exist in both files \n",
    "init_state, final_state = match_partnum(init_state, final_state)\n",
    "\n",
    "# calculate particle movement in x, y, z directions\n",
    "data_movement = []\n",
    "data_movement = final_state.iloc[:,2:5] - init_state.iloc[:,2:5]\n",
    "\n",
    "# finalize particle movement dataframe\n",
    "data_movement = pd.concat([final_state[\"part_num\"].astype(int), final_state.iloc[:,2:5],\n",
    "                           data_movement], axis=1)\n",
    "data_movement.index.name = \"\"\n",
    "data_movement.columns = ['part_num', 'x', 'y', 'z', 'movement_x', 'movement_y', 'movement_z']\n",
    "\n",
    "# preprocess dataframe\n",
    "data_movement = preprocess_movement(data_movement)\n",
    "# drop part_num 3, 4 because of excessive y-axis force\n",
    "data_movement = data_movement.drop([2,3]).reset_index(drop=True)\n",
    "data_movement.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11775, 3)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in files\n",
    "folder = \"lorss_d20out\"\n",
    "data_force = read_data_force(folder).drop([2,3])\n",
    "\n",
    "# read and averaging b-spline coefficients for eight train passes\n",
    "spline_coef = pd.DataFrame()\n",
    "\n",
    "for i in range(8):\n",
    "    if spline_coef.empty:\n",
    "        file = '../output/spline_coef_lorss_' + str(i+13) + '.csv'\n",
    "        spline_coef = pd.read_csv(file)\n",
    "        spline_coef = drop_nan(spline_coef)\n",
    "    else:\n",
    "        \n",
    "        file = '../output/spline_coef_lorss_' + str(i+13) + '.csv'\n",
    "        tmp = pd.read_csv(file)\n",
    "        tmp = drop_nan(tmp)\n",
    "        spline_coef, tmp = match_partnum(spline_coef, tmp)\n",
    "        spline_coef = spline_coef.add(tmp)/2\n",
    "\n",
    "# get particle x,y,z coordinates\n",
    "data_force = drop_nan(data_force)\n",
    "data_force, spline_coef = match_partnum(data_force, spline_coef)\n",
    "coord = data_force.iloc[:,1:4]\n",
    "\n",
    "# calculate pairwise distance between all particles\n",
    "dist = distance.cdist(coord, coord, 'euclidean')\n",
    "# get the index for the closest 19 coordinates\n",
    "top_idx = np.apply_along_axis(sort_idx, 1, dist)\n",
    "# apply spatial 3x3 gaussian kernel to all particles\n",
    "spline_kernel = apply_kernel(spline_coef, top_idx)\n",
    "\n",
    "# preprocess spline coefficients with kernel function applied\n",
    "spline_kernel_raw = np.log(np.abs(spline_kernel.iloc[:,5:25])+0.0001)\n",
    "# apply standardizaiton and PCA\n",
    "spline_kernel_std = StandardScaler().fit_transform(spline_kernel_raw)\n",
    "spline_kernel_pca = PCA(n_components=3).fit_transform(spline_kernel_std)\n",
    "spline_kernel_pca = pd.DataFrame(spline_kernel_pca)\n",
    "spline_kernel_pca.columns = ['1st dir', '2nd dir', '3rd dir']\n",
    "spline_kernel_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11775, 6)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both movement and force features\n",
    "feature = pd.concat([data_movement.iloc[:,4:7], spline_kernel_pca], axis=1)\n",
    "# standardize features for clustering\n",
    "feature_std = pd.DataFrame(columns = col_name)\n",
    "feature_std = StandardScaler().fit_transform(feature)\n",
    "feature_std = pd.DataFrame(feature_std)\n",
    "feature_std.columns = ['movement_x', 'movement_y', 'movement_z', '1st dir', '2nd dir', '3rd dir']\n",
    "feature_std.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 3436, 4: 2676, 1: 2406, 0: 1837, 2: 1420})\n"
     ]
    }
   ],
   "source": [
    "# if use spline_kernel for clustering with some preprocessing\n",
    "kmeans = cluster.KMeans(n_clusters = 5, n_init = 10, random_state = 0).fit(feature_std)\n",
    "\n",
    "# check clustering distribution\n",
    "print(Counter(kmeans.labels_))\n",
    "\n",
    "# save labels to a csv file\n",
    "label = pd.DataFrame({'part_num':spline_kernel[\"part_num\"],'label':kmeans.labels_})\n",
    "label.to_csv('../output/labels_combine_lorss.csv',header=True, index=False)\n",
    "\n",
    "# visualization\n",
    "vs.plot('../output/labels_combine_lorss.csv', 'LackofRailSeatSup.v3d','library.vlb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
